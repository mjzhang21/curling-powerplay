---
title: ""
author: "Mark Zhang"
date: last-modified
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt
---

## Data Preprocessing

Import the data.
```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import random

SEED = 42
np.random.seed(SEED)
random.seed(SEED)

df_games = pd.read_csv("../data/mxd_games.csv")
df_shots = pd.read_csv(
    "../data/mxd_shots.csv", 
    dtype={60: str, 64: str}
)
df_games.head()
```

Make all the columns lowercase.
```{python}
df_shots.columns = df_shots.columns.str.replace(r'[A-Z]', lambda m: m.group(0).lower(), regex=True)
df_shots.head()
```

Create a function that plots a proportional curling sheet containing circles,
back line and hogline.
```{python}
def plot_curling_sheet():
    """
    Plots a simple curling sheet with house circles only.
    """
    # Sheet coordinates and house radii
    CENTER_X, BUTTON_Y, BACK_Y, HOG_Y = 150, 160, 40, 580
    radii = [120, 80, 40, 10]  # house circles

    fig, ax = plt.subplots(figsize=(4, 8))

    # Draw sheet lines
    ax.axvline(CENTER_X, linestyle='--', linewidth=1)
    ax.axhline(BUTTON_Y, linestyle='--', linewidth=1)
    ax.axhline(BACK_Y, linewidth=1)
    ax.axhline(HOG_Y, linewidth=1)

    # Draw house circles
    for r in radii:
        ax.add_patch(plt.Circle((CENTER_X, BUTTON_Y), r, fill=False, color='black'))

    # Formatting
    ax.set_aspect('equal')
    ax.set_xlim(0, 300)
    ax.set_ylim(0, 600)
    ax.set_title('Curling Sheet')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    return ax

```

```{python}

df = df_shots.loc[
    (df_shots["powerplay"] == 1) &
    (df_shots["shot"].isin([2,4,6]))
].copy()

df["match_end_id"] = df["id"].astype(str) + "_" + df["game"].astype(str) + "_" + df["end"].astype(str)
df["match_id"] = df["id"].astype(str) + "_" + df["game"].astype(str)
# Hammer mask
is_t1_hammer = df["t1"].eq(df["hammer_end"])

# Teams
df["hteam"] = np.where(is_t1_hammer, df["t1"], df["t2"])
df["nhteam"] = np.where(is_t1_hammer, df["t2"], df["t1"])

# Score states
for phase in ["before", "during", "after"]:
    t1_col = f"t1{phase}"
    t2_col = f"t2{phase}"
    df[f"h_{phase}"] = np.where(is_t1_hammer, df[t1_col], df[t2_col])
    df[f"nh_{phase}"] = np.where(is_t1_hammer, df[t2_col], df[t1_col])

# Power play availability
df["h_has_pp_available"] = np.where(
    is_t1_hammer, df["t1_has_pp_available"], df["t2_has_pp_available"]
)
df["nh_has_pp_available"] = np.where(
    is_t1_hammer, df["t2_has_pp_available"], df["t1_has_pp_available"]
)


df["score_diff_before"] = df["h_before"] - df["nh_before"]
df["h_success"] = (df["h_during"] >= 2).astype(int)

```



```{python}
values_to_remove = ['Through']
df = df[~df['throw'].isin(values_to_remove)]
throw_map = {
    "Draw": "Draw", "Freeze": "Draw",
    "Guard": "Guard", "Front": "Guard",
    "Take-out": "Hit", "Double-Take-out": "Hit",
    "Hit-and-Roll": "HitRoll",
    "Raise": "Runback", "Promotion-Take-out": "Runback",
    "Wick-Soft-Peeling": "PeelClear", "Clearing": "PeelClear",
    "Through": "Other",
}
df["throw_grp"] = df["throw"].map(throw_map).fillna("Other")
```

```{python}
print(df["throw_grp"].value_counts())
```

```{python}
tab = df.groupby("throw_grp")["h_success"].agg(["mean","count"])
tab["se"] = np.sqrt(tab["mean"]*(1-tab["mean"])/tab["count"])
tab["ci_low"] = tab["mean"] - 1.96*tab["se"]
tab["ci_high"] = tab["mean"] + 1.96*tab["se"]
tab = tab.sort_values("mean", ascending=False)
tab
```

## Model Summary
```{python}
import statsmodels.formula.api as smf

# Keep only rows with needed columns
df2 = df.dropna(subset=["h_success", "percent", "throw_grp", "end", "score_diff_before", "match_end_id"]).copy()
df2["h_success"] = df2["h_success"].astype(int)

# Percent (ordered for readability; baseline forced in formula)
df2["percent"] = pd.Categorical(df2["percent"], categories=[0, 25, 50, 75, 100], ordered=True)

# End: merge 2 and 3 -> 4, then group into <=5 / 6 / 7 / 8 (baseline forced in formula)
end_int = df2["end"].astype(int).replace({2: 4, 3: 4})
df2["end_grp"] = np.select(
    [end_int <=4, end_int == 5, end_int == 6, end_int == 7, end_int == 8],
    ["<=4","5", "6", "7", "8"],
    default=np.nan
)
df2 = df2.dropna(subset=["end_grp"]).copy()
df2["end_grp"] = pd.Categorical(df2["end_grp"], categories=["6", "<=4","5", "7", "8"], ordered=False)

# Throw groups
df2["throw_grp"] = pd.Categorical(
    df2["throw_grp"],
    categories=["Draw", "Guard", "Hit", "HitRoll", "PeelClear", "Runback"],
    ordered=False
)
bins = [-np.inf, -5, -2, 1, 3, np.inf]
labels = ["<=-5", "-4to-2", "-1to+1", "+2to+3", ">=+4"]

df2["sd_bin"] = pd.cut(
    df2["score_diff_before"].astype(int),
    bins=bins,
    labels=labels,
    include_lowest=True
)

# Make it a categorical with your preferred reference first
# (so Treatment(reference="-1to+1") works cleanly / readable ordering)
df2["sd_bin"] = pd.Categorical(
    df2["sd_bin"],
    categories=["-1to+1", "<=-5", "-4to-2", "+2to+3", ">=+4"],
    ordered=False
)

```

```{python}
# --- percent mean (scaled by 25) + throw mix end-level ---

# make sure percent is numeric for averaging
df2["percent_num"] = pd.to_numeric(df2["percent"])

throw_dum = pd.get_dummies(df2["throw_grp"], prefix="throw")

tmp = pd.concat(
    [df2[["match_id","match_end_id", "h_success", "end_grp", "sd_bin", "percent_num"]], throw_dum],
    axis=1
)

end_df = tmp.groupby("match_end_id", as_index=False).agg(
    match_id=("match_id", "first"), 
    h_success=("h_success", "max"),
    end_grp=("end_grp", "first"),
    sd_bin=("sd_bin", "first"),
    n_shots=("h_success", "size"),
    pct_mean=("percent_num", "mean"),
    **{c: (c, "sum") for c in throw_dum.columns}
)
end_df = end_df[end_df["n_shots"] == 3].copy()
# scale so 1 unit = 25 points (one step)
end_df["pct_mean25"] = end_df["pct_mean"] / 25

# throw counts -> proportions
throw_cols = list(throw_dum.columns)
end_df[throw_cols] = end_df[throw_cols].div(end_df["n_shots"], axis=0)

```

```{python}
# print all value_counts without truncation
import pandas as pd
pd.set_option("display.max_rows", None)
pd.set_option("display.max_columns", None)
pd.set_option("display.width", 200)

print("\n[h_success]")
print(end_df["h_success"].value_counts(dropna=False).sort_index())

print("\n[end_grp]")
print(end_df["end_grp"].value_counts(dropna=False).sort_index())

print("\n[sd_bin]")
print(end_df["sd_bin"].value_counts(dropna=False).sort_index())

# execution bins from pct_mean
end_df["pct_bin"] = pd.cut(
    end_df["pct_mean"],
    bins=[-float("inf"), 25, 50, 75, 100],
    labels=["<=25", "(25,50]", "(50,75]", "(75,100]"],
    include_lowest=True
)
print("\n[pct_bin]")
print(end_df["pct_bin"].value_counts(dropna=False).sort_index())

# shot-mix counts (0..n_shots) for each throw type
n_shots = int(end_df["n_shots"].mode().iloc[0])
throw_cols = [c for c in end_df.columns if c.startswith("throw_")]

for c in throw_cols:
    cnt = (end_df[c] * n_shots).round().astype(int)
    print(f"\n[{c} counts per end (0..{n_shots})]")
    print(cnt.value_counts(dropna=False).sort_index())
```
```{python}
throw_baseline = "throw_Draw"
throw_terms = [c for c in throw_cols if c != throw_baseline]
rhs_terms = ["pct_mean25"] + throw_terms + [
    'C(end_grp, Treatment(reference="6"))',
    'C(sd_bin)'
    # 'n_shots',  # optional control
]

formula = "h_success ~ " + " + ".join(rhs_terms)
print(formula)
model = smf.logit(formula, data=end_df).fit(
    disp=0,
    cov_type="cluster",
    cov_kwds={"groups": end_df["match_id"]}
)
print(model.summary())

conf = model.conf_int()
or_ci = pd.DataFrame({
    "OR": np.exp(model.params),
    "CI_low": np.exp(conf[0]),
    "CI_high": np.exp(conf[1]),
})
print(or_ci)
```


## Prediction/ Classification
```{python}
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf

# end_df is your END-LEVEL dataframe (1 row per match_end_id)
# with columns: h_success, pct_mean25, end_grp, score_bin, n_shots, throw_* proportions

# -----------------------------
# Group split (by GAME/MATCH if you have it; otherwise match_end_id is fine)
# -----------------------------
group_col = "game" if "game" in end_df.columns else "match_end_id"

gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)
train_idx, test_idx = next(gss.split(end_df, y=end_df["h_success"], groups=end_df[group_col]))

train_df = end_df.iloc[train_idx].copy()
test_df  = end_df.iloc[test_idx].copy()

# -----------------------------
# Fit the CORRECT end-level model
# (drop throw_Draw baseline)
# -----------------------------
throw_cols = [c for c in end_df.columns if c.startswith("throw_")]
throw_baseline = "throw_Draw"
throw_terms = [c for c in throw_cols if c != throw_baseline]

rhs_terms = ["pct_mean25"] + throw_terms + [
    'C(end_grp, Treatment(reference="6"))'
    ,'C(sd_bin)',

    # 'n_shots',  # optional control
]
formula = "h_success ~ " + " + ".join(rhs_terms)
print("Formula:", formula)

m = smf.logit(formula, data=train_df).fit(disp=0)

# -----------------------------
# Predict + classify
# -----------------------------
p_test = m.predict(test_df)
y_test = test_df["h_success"].astype(int).values

thr = 0.5
y_pred = (p_test >= thr).astype(int)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification report (threshold=0.5):\n")
print(classification_report(y_test, y_pred, digits=3))

# -----------------------------
# ROC + AUC
# -----------------------------
fpr, tpr, thresholds = roc_curve(y_test, p_test)
auc = roc_auc_score(y_test, p_test)
print("Test AUC:", auc)

plt.figure()
plt.plot(fpr, tpr, label=f"ROC (AUC = {auc:.3f})")
plt.plot([0, 1], [0, 1], linestyle="--", label="Chance")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (Test Set) - End Level")
plt.legend()
plt.show()
```


```{python}
# Quick correlation matrix (numeric predictors only)
import numpy as np
import pandas as pd

# pick predictors you actually use (edit if needed)
num_cols = ["pct_mean25", "score_diff_before"] + [c for c in end_df.columns if c.startswith("throw_")]

X = end_df[num_cols].astype(float)

corr = X.corr()

# show full matrix (rounded)
print("Correlation matrix (rounded to 3):")
print(corr.round(3))

# show the strongest absolute correlations (excluding diagonal)
abs_corr = corr.abs()
np.fill_diagonal(abs_corr.values, 0)

top_pairs = (
    abs_corr.stack()
      .sort_values(ascending=False)
      .head(15)
)

print("\nTop 15 absolute correlations among predictors:")
print(top_pairs)
```

