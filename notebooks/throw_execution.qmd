---
title: ""
author: "Mark Zhang"
date: last-modified
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt
---

## Data Preprocessing

Import the data.
```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import random

SEED = 42
np.random.seed(SEED)
random.seed(SEED)

df_games = pd.read_csv("../data/mxd_games.csv")
df_shots = pd.read_csv(
    "../data/mxd_shots.csv", 
    dtype={60: str, 64: str}
)
df_games.head()
```

Make all the columns lowercase.
```{python}
df_shots.columns = df_shots.columns.str.replace(r'[A-Z]', lambda m: m.group(0).lower(), regex=True)
df_shots.head()
```

Create a function that plots a proportional curling sheet containing circles,
back line and hogline.
```{python}
def plot_curling_sheet():
    """
    Plots a simple curling sheet with house circles only.
    """
    # Sheet coordinates and house radii
    CENTER_X, BUTTON_Y, BACK_Y, HOG_Y = 150, 160, 40, 580
    radii = [120, 80, 40, 10]  # house circles

    fig, ax = plt.subplots(figsize=(4, 8))

    # Draw sheet lines
    ax.axvline(CENTER_X, linestyle='--', linewidth=1)
    ax.axhline(BUTTON_Y, linestyle='--', linewidth=1)
    ax.axhline(BACK_Y, linewidth=1)
    ax.axhline(HOG_Y, linewidth=1)

    # Draw house circles
    for r in radii:
        ax.add_patch(plt.Circle((CENTER_X, BUTTON_Y), r, fill=False, color='black'))

    # Formatting
    ax.set_aspect('equal')
    ax.set_xlim(0, 300)
    ax.set_ylim(0, 600)
    ax.set_title('Curling Sheet')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    return ax

```

```{python}

df = df_shots.loc[
    (df_shots["powerplay"] == 1) &
    (df_shots["shot"].isin([2,4,6,8,10]))
].copy()

df["match_end_id"] = df["id"].astype(str) + "_" + df["game"].astype(str) + "_" + df["end"].astype(str)
# Hammer mask
is_t1_hammer = df["t1"].eq(df["hammer_end"])

# Teams
df["hteam"] = np.where(is_t1_hammer, df["t1"], df["t2"])
df["nhteam"] = np.where(is_t1_hammer, df["t2"], df["t1"])

# Score states
for phase in ["before", "during", "after"]:
    t1_col = f"t1{phase}"
    t2_col = f"t2{phase}"
    df[f"h_{phase}"] = np.where(is_t1_hammer, df[t1_col], df[t2_col])
    df[f"nh_{phase}"] = np.where(is_t1_hammer, df[t2_col], df[t1_col])

# Power play availability
df["h_has_pp_available"] = np.where(
    is_t1_hammer, df["t1_has_pp_available"], df["t2_has_pp_available"]
)
df["nh_has_pp_available"] = np.where(
    is_t1_hammer, df["t2_has_pp_available"], df["t1_has_pp_available"]
)


df["score_diff_before"] = df["h_before"] - df["nh_before"]
df["h_success"] = (df["h_during"] >= 2).astype(int)

```



```{python}
values_to_remove = ['Through']
df = df[~df['throw'].isin(values_to_remove)]
throw_map = {
    "Draw": "Draw", "Freeze": "Draw",
    "Guard": "Guard", "Front": "Guard",
    "Take-out": "Hit", "Double-Take-out": "Hit",
    "Hit-and-Roll": "HitRoll",
    "Raise": "Runback", "Promotion-Take-out": "Runback",
    "Wick-Soft-Peeling": "PeelClear", "Clearing": "PeelClear",
    "Through": "Other",
}
df["throw_grp"] = df["throw"].map(throw_map).fillna("Other")
```

```{python}
print(df["throw_grp"].value_counts())
```

```{python}
tab = df.groupby("throw_grp")["h_success"].agg(["mean","count"])
tab["se"] = np.sqrt(tab["mean"]*(1-tab["mean"])/tab["count"])
tab["ci_low"] = tab["mean"] - 1.96*tab["se"]
tab["ci_high"] = tab["mean"] + 1.96*tab["se"]
tab = tab.sort_values("mean", ascending=False)
tab
```

## Model Summary
```{python}
import statsmodels.formula.api as smf

# Keep only rows with needed columns
df2 = df.dropna(subset=["h_success", "percent", "throw_grp", "end", "score_diff_before", "match_end_id"]).copy()
df2["h_success"] = df2["h_success"].astype(int)

# Percent (ordered for readability; baseline forced in formula)
df2["percent"] = pd.Categorical(df2["percent"], categories=[0, 25, 50, 75, 100], ordered=True)

# End: merge 2 and 3 -> 4, then group into <=5 / 6 / 7 / 8 (baseline forced in formula)
end_int = df2["end"].astype(int).replace({2: 4, 3: 4})
df2["end_grp"] = np.select(
    [end_int <=4, end_int == 5, end_int == 6, end_int == 7, end_int == 8],
    ["<=4","5", "6", "7", "8"],
    default=np.nan
)
df2 = df2.dropna(subset=["end_grp"]).copy()
df2["end_grp"] = pd.Categorical(df2["end_grp"], categories=["6", "<=4","5", "7", "8"], ordered=False)

# Throw groups
df2["throw_grp"] = pd.Categorical(
    df2["throw_grp"],
    categories=["Draw", "Guard", "Hit", "HitRoll", "PeelClear", "Runback"],
    ordered=False
)

# Score bins (3 bins; baseline forced in formula)
df2["score_bin"] = pd.cut(
    df2["score_diff_before"],
    bins=[-10**9, -2, 1, 10**9],
    labels=["trailing", "close", "leading"]
)
df2["score_bin"] = pd.Categorical(df2["score_bin"], categories=["close", "trailing", "leading"], ordered=False)

# Fit logistic regression (cluster-robust SEs by match_id)
model = smf.logit(
    "h_success ~ C(percent, Treatment(reference=100))"
    " + C(throw_grp, Treatment(reference='Draw'))"
    " + C(end_grp, Treatment(reference='6'))"
    " + C(score_bin, Treatment(reference='close'))",
    data=df2
).fit(
    disp=0,
    cov_type="cluster",
    cov_kwds={"groups": df2["match_end_id"]}
)

print(model.summary())

# Odds ratios + 95% CI (exponentiate coefficients)
conf = model.conf_int()
or_ci = pd.DataFrame({
    "OR": np.exp(model.params),
    "CI_low": np.exp(conf[0]),
    "CI_high": np.exp(conf[1]),
})
print(or_ci)
```

## Prediction/ Classification
```{python}
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support
from sklearn.model_selection import GroupShuffleSplit

gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)
train_idx, test_idx = next(gss.split(df2, y=df2["h_success"], groups=df2["match_end_id"]))

train_df = df2.iloc[train_idx].copy()
test_df  = df2.iloc[test_idx].copy()

# fit
m = smf.logit(
    "h_success ~ C(percent, Treatment(reference=100))"
    " + C(throw_grp, Treatment(reference='Draw'))"
    " + C(end_grp, Treatment(reference='6'))"
    " + C(score_bin, Treatment(reference='close'))",
    data=train_df
).fit(
    disp=0,
    cov_type="cluster",
    cov_kwds={"groups": train_df["match_end_id"]}  
)

# predict probs + labels
p_test = m.predict(test_df)
y_test = test_df["h_success"].astype(int).values

thr = 0.5
y_pred = (p_test >= thr).astype(int)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification report (threshold=0.5):\n")
print(classification_report(y_test, y_pred, digits=3))
```


```{python}
from sklearn.metrics import roc_curve, roc_auc_score
# ROC curve + AUC
fpr, tpr, thresholds = roc_curve(y_test, p_test)
auc = roc_auc_score(y_test, p_test)
print("Test AUC:", auc)

plt.figure()
plt.plot(fpr, tpr, label=f"ROC (AUC = {auc:.3f})")
plt.plot([0, 1], [0, 1], linestyle="--", label="Chance")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (Test Set)")
plt.legend()
plt.show()
```


```{python}
df['h_success'].value_counts()
```