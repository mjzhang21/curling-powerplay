---
title: ""
author: "Mark Zhang"
date: last-modified
format:
  pdf:
    colorlinks: true
    linkcolor: blue
    number-sections: true
    geometry: margin=1in
    fontsize: 11pt
---

## Data Preprocessing

Import the data.
```{python}
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import random

SEED = 42
np.random.seed(SEED)
random.seed(SEED)

df_games = pd.read_csv("../data/mxd_games.csv")
df_shots = pd.read_csv(
    "../data/mxd_shots.csv", 
    dtype={60: str, 64: str}
)
df_games.head()
```

Make all the columns lowercase.
```{python}
df_shots.columns = df_shots.columns.str.replace(r'[A-Z]', lambda m: m.group(0).lower(), regex=True)
df_shots.head()
```

Create a function that plots a proportional curling sheet containing circles,
back line and hogline.
```{python}
def plot_curling_sheet():
    """
    Plots a simple curling sheet with house circles only.
    """
    # Sheet coordinates and house radii
    CENTER_X, BUTTON_Y, BACK_Y, HOG_Y = 150, 160, 40, 580
    radii = [120, 80, 40, 10]  # house circles

    fig, ax = plt.subplots(figsize=(4, 8))

    # Draw sheet lines
    ax.axvline(CENTER_X, linestyle='--', linewidth=1)
    ax.axhline(BUTTON_Y, linestyle='--', linewidth=1)
    ax.axhline(BACK_Y, linewidth=1)
    ax.axhline(HOG_Y, linewidth=1)

    # Draw house circles
    for r in radii:
        ax.add_patch(plt.Circle((CENTER_X, BUTTON_Y), r, fill=False, color='black'))

    # Formatting
    ax.set_aspect('equal')
    ax.set_xlim(0, 300)
    ax.set_ylim(0, 600)
    ax.set_title('Curling Sheet')
    ax.set_xlabel('X')
    ax.set_ylabel('Y')

    return ax

```
```{python}
df_shots = df_shots[
    df_shots.groupby(["id", "game", "end"])["shot"].transform("nunique") == 11
].copy()
```
```{python}
df_shots["match_end_id"] = df_shots["id"].astype(str) + "_" + df_shots["game"].astype(str) + "_" + df_shots["end"].astype(str)
df_shots["match_id"] = df_shots["id"].astype(str) + "_" + df_shots["game"].astype(str)
# Hammer mask
is_t1_hammer = df_shots["t1"].eq(df_shots["hammer_end"])

# Teams
df_shots["hteam"] = np.where(is_t1_hammer, df_shots["t1"], df_shots["t2"])
df_shots["nhteam"] = np.where(is_t1_hammer, df_shots["t2"], df_shots["t1"])

# Score states
for phase in ["before", "during", "after"]:
    t1_col = f"t1{phase}"
    t2_col = f"t2{phase}"
    df_shots[f"h_{phase}"] = np.where(is_t1_hammer, df_shots[t1_col], df_shots[t2_col])
    df_shots[f"nh_{phase}"] = np.where(is_t1_hammer, df_shots[t2_col], df_shots[t1_col])

# Power play availability
df_shots["h_has_pp_available"] = np.where(
    is_t1_hammer, df_shots["t1_has_pp_available"], df_shots["t2_has_pp_available"]
)
df_shots["nh_has_pp_available"] = np.where(
    is_t1_hammer, df_shots["t2_has_pp_available"], df_shots["t1_has_pp_available"]
)
```

```{python}
ends = df_shots.drop_duplicates("match_end_id").copy()

# 2) end-level indicators (same as your definitions)
ends["HE"] = (ends["h_during"] >= 2).astype(int)     # hammer scores 2+
ends["FE"] = (ends["h_during"] <= 1).astype(int)     # non-hammer holds hammer to 0/1
ends["SE"] = (ends["nh_during"] >= 1).astype(int)    # non-hammer scores 1+

# 3) make team-end rows (2 rows per end: one for hammer team, one for non-hammer team)
hammer_rows = pd.DataFrame({
    "team": ends["hteam"],
    "HE": ends["HE"],          # defined when you HAVE hammer
    "FE": np.nan,
    "SE": np.nan,
})

nonhammer_rows = pd.DataFrame({
    "team": ends["nhteam"],
    "HE": np.nan,
    "FE": ends["FE"],          # defined when you DON'T have hammer
    "SE": ends["SE"],
})

team_end = pd.concat([hammer_rows, nonhammer_rows], ignore_index=True)

# 4) team-level rates (averages over eligible ends)
team_rates = team_end.groupby("team", as_index=False).agg(
    HE=("HE","mean"),
    FE=("FE","mean"),
    SE=("SE","mean"),
    n_HE=("HE","count"),
    n_FE=("FE","count"),
    n_SE=("SE","count"),
)

# 5) weighted average team strength
w_HE, w_FE, w_SE = 1/3, 1/3, 1/3
team_rates["strength"] = (
    w_HE * team_rates["HE"] +
    w_FE * team_rates["FE"] +
    w_SE * team_rates["SE"]
)

# 6) merge team-level strength back onto shot-level df_shots (optional)
# (this gives each shot row the strength of its hammer team and non-hammer team)
df_shots = df_shots.merge(team_rates[["team","strength"]], left_on="hteam", right_on="team", how="left") \
                   .rename(columns={"strength":"hteam_strength"}).drop(columns=["team"])

df_shots = df_shots.merge(team_rates[["team","strength"]], left_on="nhteam", right_on="team", how="left") \
                   .rename(columns={"strength":"nhteam_strength"}).drop(columns=["team"])


```


```{python}
df_shots["strength_diff"] = df_shots["hteam_strength"] - df_shots["nhteam_strength"]


df_shots["score_diff_before"] = df_shots["h_before"] - df_shots["nh_before"]
df_shots["h_success"] = (df_shots["h_during"] >= 2).astype(int)
df = df_shots.loc[
    (df_shots["powerplay"] == 1) &
    (df_shots["shot"].isin([2,4,6]))
].copy()
```

```{python}
values_to_remove = ['Through']
df = df[~df['throw'].isin(values_to_remove)]
throw_map = {
    "Draw": "Draw", "Freeze": "Draw",
    "Guard": "Guard", "Front": "Guard",

    "Take-out": "Removal",
    "Double-Take-out": "Removal",
    "Hit-and-Roll": "Removal",
    "Promotion-Take-out": "Removal",
    "Clearing": "Removal",

    "Wick-Soft-Peeling": "Peel/Raise",
    "Raise": "Peel/Raise"
}
df["throw_grp"] = df["throw"].map(throw_map).fillna("Other")
```



## Model Summary
```{python}
import statsmodels.formula.api as smf

# Keep only rows with needed columns
df2 = df.dropna(subset=["h_success", "percent", "throw_grp", "end", "score_diff_before", "strength_diff","match_end_id"]).copy()
df2["h_success"] = df2["h_success"].astype(int)

# Percent (ordered for readability; baseline forced in formula)
df2["percent"] = pd.Categorical(df2["percent"], categories=[0, 25, 50, 75, 100], ordered=True)
df2["percent_num"] = pd.to_numeric(df2["percent"])
# End: merge 2 and 3 -> 4, then group into <=5 / 6 / 7 / 8 (baseline forced in formula)
end_int = df2["end"].astype(int).replace({2: 4, 3: 4})
df2["end_grp"] = np.select(
    [end_int <=4, end_int == 5, end_int == 6, end_int == 7, end_int == 8],
    ["<=4","5", "6", "7", "8"],
    default=np.nan
)
df2 = df2.dropna(subset=["end_grp"]).copy()
df2["end_grp"] = pd.Categorical(df2["end_grp"], categories=["6", "<=4","5", "7", "8"], ordered=False)

df2["throw_grp"] = pd.Categorical(
    df2["throw_grp"],
    categories=["Draw", "Guard", "Removal", "Peel/Raise"],
    ordered=False
)
```

```{python}
ct = pd.crosstab(df2["shot"], df2["throw_grp"])
print(ct)
```
```{python}
throw_dum = pd.get_dummies(df2["throw_grp"], prefix="throw")

tmp = pd.concat(
    [df2[["match_id","match_end_id", "h_success", "end_grp", "score_diff_before", "percent_num","strength_diff"]], throw_dum],
    axis=1
)

end_df = tmp.groupby("match_end_id", as_index=False).agg(
    match_id=("match_id", "first"), 
    h_success=("h_success", "max"),
    strength_diff=("strength_diff", "first"),
    end_grp=("end_grp", "first"),
    score_diff_before=("score_diff_before", "first"),
    n_shots=("h_success", "size"),
    pct_mean=("percent_num", "mean"),
    **{c: (c, "sum") for c in throw_dum.columns}
)

end_df["pct_mean25"] = end_df["pct_mean"] / 25
end_df["strength_diff_z"] = (end_df["strength_diff"] - end_df["strength_diff"].mean()) / end_df["strength_diff"].std()
end_df["score_diff_before_c"] = end_df["score_diff_before"] - end_df["score_diff_before"].mean()
```
```{python}
end_shot = (
    df2.groupby(["match_end_id", "shot"], as_index=False)
       .agg(
           shot_percent=("percent_num", "mean"),
           shot_throwgrp=("throw_grp", lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0])
       )
)

wide = end_shot.pivot(index="match_end_id", columns="shot")
wide.columns = [f"s{shot}_{name}" for name, shot in wide.columns]
wide = wide.reset_index()

wide = wide.rename(columns={
    "s2_shot_percent": "s2_percent",
    "s4_shot_percent": "s4_percent",
    "s6_shot_percent": "s6_percent",
    "s2_shot_throwgrp": "s2_throwgrp",
    "s4_shot_throwgrp": "s4_throwgrp",
    "s6_shot_throwgrp": "s6_throwgrp",
})

# optional: scale these too (same idea as pct_mean25)
wide["s2_percent25"] = wide["s2_percent"] / 25
wide["s4_percent25"] = wide["s4_percent"] / 25
wide["s6_percent25"] = wide["s6_percent"] / 25

end_df = end_df.merge(wide, on="match_end_id", how="left")

end_df.loc[end_df["s2_throwgrp"] == "Removal", "s2_throwgrp"] = np.nan
for s in [2,4,6]:
    col = f"s{s}_throwgrp"
    end_df[col] = end_df[col].astype("category").cat.remove_unused_categories()

# optional: categorical dtype
for s in [2,4,6]:
    end_df[f"s{s}_throwgrp"] = end_df[f"s{s}_throwgrp"].astype("category")
```


```{python}
import numpy as np
import pandas as pd
import statsmodels.formula.api as smf

shot_percent_terms = ["s2_percent25", "s4_percent25", "s6_percent25"]

shot_throw_terms = [
    'C(s2_throwgrp, Treatment(reference="Draw"))',
    'C(s4_throwgrp, Treatment(reference="Draw"))',
    'C(s6_throwgrp, Treatment(reference="Draw"))'
]

other_terms = [
    'C(end_grp, Treatment(reference="6"))',
    'score_diff_before_c',
    'strength_diff_z'
]

rhs_terms = shot_percent_terms + shot_throw_terms + other_terms
formula = "h_success ~ " + " + ".join(rhs_terms)
print(formula)

# only require columns actually used (categoricals can stay as object/category)
needed_cols = (
    ["h_success", "end_grp", "score_diff_before_c", "strength_diff_z"] +
    shot_percent_terms + ["s2_throwgrp", "s4_throwgrp", "s6_throwgrp"]
)

df_model = end_df.dropna(subset=needed_cols).copy()
df_model["h_success"] = df_model["h_success"].astype(int)

for c in ["s2_throwgrp","s4_throwgrp","s6_throwgrp","end_grp"]:
    df_model[c] = df_model[c].astype("category").cat.remove_unused_categories()

# Fit
model = smf.logit(formula=formula, data=df_model).fit(disp=0)
print(model.summary())

# Odds ratios + CI
conf = model.conf_int()
or_ci = pd.DataFrame({
    "OR": np.exp(model.params),
    "CI_low": np.exp(conf[0]),
    "CI_high": np.exp(conf[1]),
})
print(or_ci.sort_values("OR", ascending=False))
```

```{python}


## Prediction/ Classification
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, roc_auc_score
import matplotlib.pyplot as plt
import pandas as pd
import statsmodels.formula.api as smf

group_col = "game" if "game" in end_df.columns else "match_end_id"
gss = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=42)
train_idx, test_idx = next(gss.split(end_df, y=end_df["h_success"], groups=end_df[group_col]))

train_df = end_df.iloc[train_idx].copy()
test_df  = end_df.iloc[test_idx].copy()

shot_percent_terms = ["s2_percent25", "s4_percent25", "s6_percent25"]
needed_cols = (
    ["h_success", "end_grp", "score_diff_before_c", "strength_diff_z"] +
    shot_percent_terms + ["s2_throwgrp", "s4_throwgrp", "s6_throwgrp"]
)

formula = (
    "h_success ~ " +
    " + ".join(
        shot_percent_terms + [
            'C(s2_throwgrp, Treatment(reference="Draw"))',
            'C(s4_throwgrp, Treatment(reference="Draw"))',
            'C(s6_throwgrp, Treatment(reference="Draw"))',
            'C(end_grp, Treatment(reference="6"))',
            'score_diff_before_c',
            'strength_diff_z'
        ]
    )
)
print(formula)

# --- drop NA separately in train/test using the same required columns ---
train_model = train_df.dropna(subset=needed_cols).copy()
test_model  = test_df.dropna(subset=needed_cols).copy()

train_model["h_success"] = train_model["h_success"].astype(int)
test_model["h_success"]  = test_model["h_success"].astype(int)

# --- make categorical + remove unused categories on TRAIN (important) ---
for c in ["s2_throwgrp","s4_throwgrp","s6_throwgrp","end_grp"]:
    train_model[c] = train_model[c].astype("category").cat.remove_unused_categories()
    # align test to train's categories (unknown categories -> NaN -> drop)
    test_model[c] = pd.Categorical(test_model[c], categories=train_model[c].cat.categories)

# after aligning categories, drop rows that became NaN in categoricals
test_model = test_model.dropna(subset=["s2_throwgrp","s4_throwgrp","s6_throwgrp","end_grp"]).copy()

# --- fit on TRAIN only ---
model = smf.logit(formula=formula, data=train_model).fit(disp=0)

# --- predict on TEST only ---
p_test = model.predict(test_model)
y_test = test_model["h_success"].values

thr = 0.5
y_pred = (p_test >= thr).astype(int)

print("Train n:", len(train_model), " Test n:", len(test_model))
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification report (thr=0.5):\n", classification_report(y_test, y_pred, digits=3))

fpr, tpr, _ = roc_curve(y_test, p_test)
auc = roc_auc_score(y_test, p_test)
print("Test AUC:", auc)

plt.figure()
plt.plot(fpr, tpr, label=f"ROC (AUC = {auc:.3f})")
plt.plot([0, 1], [0, 1], linestyle="--", label="Chance")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve (Test Set)")
plt.legend()
plt.show()
```


```{python}
import numpy as np
import pandas as pd
import patsy
from statsmodels.stats.outliers_influence import variance_inflation_factor

# same formula you fit
formula = (
    'h_success ~ s2_percent25 + s4_percent25 + s6_percent25'
    ' + C(s2_throwgrp, Treatment(reference="Draw"))'
    ' + C(s4_throwgrp, Treatment(reference="Draw"))'
    ' + C(s6_throwgrp, Treatment(reference="Draw"))'
    ' + C(end_grp, Treatment(reference="6"))'
    ' + score_diff_before_c + strength_diff_z'
)

# build design matrices (Patsy does all the dummy coding)
y, X = patsy.dmatrices(formula, data=df_model, return_type="dataframe")

# drop intercept for VIF
X_noI = X.drop(columns=["Intercept"], errors="ignore")

vif = pd.DataFrame({
    "term": X_noI.columns,
    "VIF": [variance_inflation_factor(X_noI.values, i) for i in range(X_noI.shape[1])]
}).sort_values("VIF", ascending=False)

print(vif.head(25))
print("\nMax VIF:", vif["VIF"].max())
```

```{python}
import numpy as np
import pandas as pd

def make_label_map():
    label_map = {
        "Intercept": "Intercept",
        "s2_percent25": "Shot 2 execution (per +25)",
        "s4_percent25": "Shot 4 execution (per +25)",
        "s6_percent25": "Shot 6 execution (per +25)",
        "score_diff_before_c": "Pre-end score diff (per +1)",
        "strength_diff_z": "Strength diff (per +1 SD)",
    }

    # Throw groups (ref = Draw)
    for shot in [2, 4, 6]:
        base = f'C(s{shot}_throwgrp, Treatment(reference="Draw"))'
        label_map[f'{base}[T.Guard]'] = f"Shot {shot} call: Guard (vs Draw)"
        label_map[f'{base}[T.Removal]'] = f"Shot {shot} call: Removal (vs Draw)"
        label_map[f'{base}[T.Peel/Raise]'] = f"Shot {shot} call: Peel/Raise (vs Draw)"
        # common alternate spellings
        label_map[f'{base}[T.PeelRaise]'] = f"Shot {shot} call: Peel/Raise (vs Draw)"
        label_map[f'{base}[T.Peel_Raise]'] = f"Shot {shot} call: Peel/Raise (vs Draw)"

    # End group (ref = 6)
    end_base = 'C(end_grp, Treatment(reference="6"))'
    label_map[f'{end_base}[T.<=4]'] = r"End group $\le$4 (vs 6)"
    label_map[f'{end_base}[T.5]']   = "End group 5 (vs 6)"
    label_map[f'{end_base}[T.7]']   = "End group 7 (vs 6)"
    label_map[f'{end_base}[T.8]']   = "End group 8 (vs 6)"

    return label_map


def logit_or_latex(
    res,
    label_map=None,
    drop_intercept=True,
    alpha=0.05,
    sort=False,
    caption=r"Multivariable logistic regression for Power Play hammer-end success (scoring $\ge$ 2). Execution is per 25 points.",
    label="tab:pp_hammer_success",
    file_path="pp_hammer_success_table.tex"
):
    params = res.params.copy()
    conf = res.conf_int(alpha=alpha)
    pvals = res.pvalues.copy()

    df = pd.DataFrame({
        "OR": np.exp(params),
        "CI_low": np.exp(conf[0]),
        "CI_high": np.exp(conf[1]),
        "p": pvals
    })

    if drop_intercept and "Intercept" in df.index:
        df = df.drop(index="Intercept")

    # Nicer row names
    if label_map is not None:
        df = df.rename(index=label_map)

    # If any leftover Unicode sneaks in, convert to LaTeX-safe
    df.index = (
        pd.Index(df.index)
        .str.replace("≥", r"$\ge$", regex=False)
        .str.replace("≤", r"$\le$", regex=False)
    )

    # Format display columns
    df["OR (95\\% CI)"] = df.apply(
        lambda r: f'{r["OR"]:.2f} [{r["CI_low"]:.2f}, {r["CI_high"]:.2f}]',
        axis=1
    )
    df["p"] = df["p"].map(lambda x: r"$<0.001$" if x < 0.001 else f"{x:.3f}")

    out = df[["OR (95\\% CI)", "p"]]

    if sort:
        out = out.loc[df["OR"].sort_values(ascending=False).index]

    # Generate LaTeX with booktabs + centering (matches your pasted style)
    latex = out.to_latex(
        index=True,
        escape=False,
        column_format="lcc",
        caption=caption,
        label=label,
        bold_rows=False,
        na_rep="",

    )


    latex = latex.replace("\\begin{table}", "\\begin{table}\n\\centering", 1)

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(latex)

    return out, latex
```

```{python}
label_map = make_label_map()

or_table, latex_str = logit_or_latex(
    model,
    label_map=label_map,
    drop_intercept=True,
    sort=False,
    file_path="pp_hammer_success_table.tex"
)

print(latex_str)
```

```{python}
import numpy as np
import pandas as pd

# --- Descriptive table: counts by shot x throw group ---
# Assumes df2 has columns: shot (2/4/6) and throw_grp (Draw/Guard/Removal/Peel/Raise)

# Make sure ordering is stable
shot_order = [2, 4, 6]
grp_order = ["Draw", "Guard", "Removal", "Peel/Raise"]

ct = pd.crosstab(df2["shot"], df2["throw_grp"]).reindex(index=shot_order, columns=grp_order, fill_value=0)

# Add within-shot percentages (row %)
row_pct = ct.div(ct.sum(axis=1), axis=0) * 100

# Build a compact display table: "count (pct)"
disp = ct.astype(int).astype(str) + " (" + row_pct.round(1).astype(str) + r"\%)"

# Add totals
disp["Total"] = ct.sum(axis=1).astype(int).astype(str)
disp.loc["Total"] = list(ct.sum(axis=0).astype(int).astype(str)) + [str(int(ct.values.sum()))]

# Rename index for LaTeX
disp.index = [f"Shot {i}" if isinstance(i, int) else i for i in disp.index]
disp.columns = ["Draw", "Guard", "Removal", "Peel/Raise", "Total"]

# Export to LaTeX
latex_desc = disp.to_latex(
    index=True,
    escape=False,                 # keep \% as LaTeX
    column_format="l" + "c"*len(disp.columns),
    caption="Distribution of hammer-team shot calls by shot number in Power Play ends. Entries are count (within-shot \\%).",
    label="tab:pp_throw_dist",
    bold_rows=False
)

# Add centering after begin{table}
latex_desc = latex_desc.replace("\\begin{table}", "\\begin{table}\n\\centering", 1)

with open("pp_throw_dist.tex", "w", encoding="utf-8") as f:
    f.write(latex_desc)

print(latex_desc)
```